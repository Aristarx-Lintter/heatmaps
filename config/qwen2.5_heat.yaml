project:
  name: "Heatmaps"
  experiment_name: "MiddleInjection-upd-transcribation-visual-merger"
  hf_checkpoint: "Archistrax/Qwen2-5-VL-middle-injection-checkpoints"

clearml:
  project_name: ${project.name}
  task_name: ${project.experiment_name}
  output_uri: false
  reuse_last_task_id: true

dataset:
  name: "Archistrax/processed_transcribations"
  kwargs:
    transcribation_feature_name: "upd_transcribation"
    calibration_feature_name: "model_description"
    calib_prob: 0.2
  # name: "set_eye_dataset_off"
  # name: "dried_heatmaps"

model:
  name: "Qwen/Qwen2.5-VL-3B-Instruct"
  kwargs:
    torch_dtype: "bfloat16"
    device_map: "cuda"
    attn_implementation: "flash_attention_2"
    trust_remote_code: true

trainer:
  output_dir: "./middle_injection_visual_merger_qwen2.5-checkpoints"
  num_train_epochs: 50
  per_device_train_batch_size: 18
  per_device_eval_batch_size: 12
  gradient_accumulation_steps: 2
  learning_rate: 8e-6
  weight_decay: 0.01
  lr_scheduler_type: "linear"
  warmup_steps: 20
  logging_steps: 2
  save_steps: 
  save_strategy: "steps"
  bf16: true
  fp16: false
  gradient_checkpointing: true
  optim: "adamw_8bit"
  push_to_hub: true
  hub_model_id: ${project.hf_checkpoint}
  eval_strategy: "steps"
  eval_steps: 100
  remove_unused_columns: false
  dataloader_num_workers: 12
  # max_grad_norm: 1.0

lora:
  r: 64
  lora_alpha: 128
  lora_dropout: 0.1
  bias: "none"
  target_modules_patterns:
    # - "heat_embedding\\.linear[12]"       # heat_embedding.linear1 и heat_embedding.linear2
    - "visual\\.merger\\.mlp\\.[02]"         # visual.merger.mlp.0 и visual.merger.mlp.2
    # - "visual\\.heat_block\\.(attn_self\\.(qkv|proj)|attn_cross\\.(q|kv)|mlp\\.(gate_proj|up_proj|down_proj))"
    - "visual\\.blocks\\.2[3-9]\\.(attn\\.(qkv|proj)|mlp\\.(gate_proj|up_proj|down_proj))" 
    - "visual\\.blocks\\.3[01]\\.(attn\\.(qkv|proj)|mlp\\.(gate_proj|up_proj|down_proj))" 
    # - "model\\.layers\\.\\d+\\.self_attn\\.(q_proj|k_proj|v_proj|o_proj)" # Все self_attn проекции в языковой модели
    # - "model\\.layers\\.\\d+\\.mlp\\.(gate_proj|up_proj|down_proj)"       # Все mlp проекции в языковой модели