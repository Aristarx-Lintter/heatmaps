{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5dcf98-67a2-4b9a-b95b-4e8213744c8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8689cf15a1c8497db30115a6b326560c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "path = \"./Qwen2.5-VL-3B-Instruct\"\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e337f3-b31b-4320-ae26-3865413ed2f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-23 08:13:30 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 04-23 08:13:37 [config.py:689] This model supports multiple tasks: {'embed', 'score', 'classify', 'generate', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 04-23 08:13:37 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "INFO 04-23 08:13:38 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='./Qwen2.5-VL-3B-Instruct', speculative_config=None, tokenizer='./Qwen2.5-VL-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=128000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=./Qwen2.5-VL-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 04-23 08:13:39 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f29236ff610>\n",
      "INFO 04-23 08:13:39 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-23 08:13:39 [cuda.py:221] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-23 08:13:42 [gpu_model_runner.py:1276] Starting to load model ./Qwen2.5-VL-3B-Instruct...\n",
      "INFO 04-23 08:13:42 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]\n",
      "WARNING 04-23 08:13:42 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092e50927f0941449e807cb0df52b85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-23 08:14:01 [loader.py:458] Loading weights took 18.97 seconds\n",
      "INFO 04-23 08:14:01 [gpu_model_runner.py:1291] Model loading took 7.1557 GiB and 19.168695 seconds\n",
      "INFO 04-23 08:14:02 [gpu_model_runner.py:1560] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.\n",
      "INFO 04-23 08:14:13 [backends.py:416] Using cache directory: /root/.cache/vllm/torch_compile_cache/8710f34e70/rank_0_0 for vLLM's torch.compile\n",
      "INFO 04-23 08:14:13 [backends.py:426] Dynamo bytecode transform time: 6.90 s\n",
      "INFO 04-23 08:14:16 [backends.py:132] Cache the graph of shape None for later use\n",
      "INFO 04-23 08:14:42 [backends.py:144] Compiling a graph for general shape takes 28.40 s\n",
      "INFO 04-23 08:14:58 [monitor.py:33] torch.compile takes 35.30 s in total\n",
      "INFO 04-23 08:14:59 [kv_cache_utils.py:634] GPU KV cache size: 510,912 tokens\n",
      "INFO 04-23 08:14:59 [kv_cache_utils.py:637] Maximum concurrency for 128,000 tokens per request: 3.99x\n",
      "INFO 04-23 08:15:25 [gpu_model_runner.py:1626] Graph capturing finished in 26 secs, took 0.71 GiB\n",
      "INFO 04-23 08:15:25 [core.py:163] init engine (profile, create kv cache, warmup model) took 84.16 seconds\n",
      "INFO 04-23 08:15:26 [core_client.py:435] Core engine process 0 ready.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "from vllm import LLM, SamplingParams\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "path = \"./Qwen2.5-VL-3B-Instruct\"\n",
    "\n",
    "target_answer = \"\"\"Describe the visible content of this image shortly, objectively and factually **as a single, continuous paragraph of prose.** Focus on the main subjects or elements present. Note their key visual characteristics (e.g., color, shape, texture if prominent) and their spatial arrangement or relationship to one another. If any actions or interactions are depicted, describe them simply.\n",
    "\n",
    "**Crucially, do NOT use any structural formatting:**\n",
    "*   Avoid bullet points, numbered lists, or any list-like structures.\n",
    "*   Do not use introductory phrases that signal a list or structure (e.g., \"Key elements include:\", \"The characteristics are:\", \"Present are:\").\n",
    "*   Do not use section headings or labels within the description.\n",
    "\n",
    "Integrate all descriptive details smoothly into the narrative paragraph. Stick strictly to what is visually present. Avoid interpretations, assumptions, artistic analysis, or personal opinions. Make the description short.\n",
    "\"\"\"\n",
    "\n",
    "llm = LLM(\n",
    "    model=path,\n",
    "    limit_mm_per_prompt={\"image\": 1, \"video\": 0},\n",
    "    gpu_memory_utilization=0.4\n",
    ")\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65ffa2d-2e63-47f6-9939-cd237a0c3768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['human_id', 'image', 'suffix', 'heatmap', 'transcribation', 'audio_file', 'asc_file'],\n",
       "    num_rows: 833\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "data = Dataset.load_from_disk(\"dried_heatmaps\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d03876-e487-4842-a034-d982b669ce06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113a146c75a042978e69bad04d84668f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|                                                                                      â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.common.templates import messages_template\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(path)\n",
    "\n",
    "def make_answer_vllm(features):\n",
    "    messages = []\n",
    "    for feature in features:\n",
    "        prompts = messages_template(feature[\"image\"], \"\")[:1]\n",
    "        prompts[0]['content'][1]['text'] = target_answer\n",
    "        messages.append(prompts)\n",
    "\n",
    "    prompts = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, _ = process_vision_info(messages)\n",
    "    \n",
    "    inputs = []\n",
    "    for image_input, prompt in zip(image_inputs, prompts):\n",
    "        mm_data = {}\n",
    "        if image_input is not None:\n",
    "            mm_data[\"image\"] = image_input\n",
    "        \n",
    "        inputs.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"multi_modal_data\": mm_data,\n",
    "        })\n",
    "    outputs = llm.generate(inputs, sampling_params=sampling_params)\n",
    "    results = [out.outputs[0].text for out in outputs]\n",
    "    return {\"updated_transcribations\": results}\n",
    "\n",
    "\n",
    "messages = make_answer_vllm(data.select(range(10)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee343cf-7589-4990-aa35-ebffc127ab9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image features a vibrant and abstract composition with a predominantly red background. Various colorful flowers and leaves are scattered throughout, each with distinct shapes and colors. The flowers include shades of blue, green, pink, and purple, with some appearing as three-petaled blossoms and others as more complex, multi-petaled forms. The leaves are depicted in green and blue hues, adding to the overall lush and dynamic feel of the scene. The arrangement of the flowers and leaves is somewhat random, creating a sense of natural randomness and spontaneity. The image lacks any clear focal point, instead presenting a harmonious blend of colors and shapes that evoke a sense of movement and life.\n",
      "The image depicts a serene coastal scene with a vibrant pink flowering tree in the foreground. The tree's lush green leaves contrast beautifully with the bright pink blossoms. In the background, a calm blue body of water reflects the sky and the surrounding landscape. The sky is dotted with fluffy white clouds, and the horizon is lined with a mix of greenery and a few buildings, possibly houses or small structures. The overall composition creates a tranquil and picturesque setting.\n",
      "In a kitchen setting, three men stand near a counter. The man on the left wears a white shirt and holds a green cloth. The man in the middle is dressed in a black shirt and jeans, holding a glass. The man on the right is in a light blue shirt and dark pants. Behind them, a window with a white frame and a shelf with various items, including a green bottle and a blue object, is visible. The counter holds a pot and a kettle. The scene is casual, with the men seemingly engaged in a conversation or activity.\n",
      "The image depicts a futuristic, digital environment with a grid-like structure. The walls and ceiling are composed of vertical and horizontal lines, creating a pattern of stripes in shades of blue, purple, and orange. The floor mirrors this pattern, with horizontal stripes that reflect the colors of the walls. In the center, there are illuminated panels with a grid of red and blue lights, adding to the high-tech ambiance. The overall atmosphere is sleek and modern, with a sense of depth and complexity due to the interplay of light and shadow.\n",
      "The image features a detailed illustration of a hamburger. The top bun is a golden-brown, sesame-seeded roll, while the bottom bun is a lighter shade, also sesame-seeded. Between the buns, there is a slice of cheese, a layer of lettuce, a slice of tomato, a slice of onion, and a patty. The patty is brown and appears to be cooked. The entire burger is presented against a plain, light gray background.\n",
      "The image shows a rifle lying on a textured surface, possibly a carpet. The rifle has a wooden stock and a metal barrel. The stock is dark brown, and the metal parts, including the trigger and the bolt, are silver. There is a strap attached to the rifle, likely for carrying. The rifle appears to be a semi-automatic or automatic firearm, given its design and the presence of a bolt. The background is a plain, light-colored surface, which contrasts with the darker tones of the rifle.\n",
      "The image depicts a simple, black-and-white line drawing of a car. The car is shown from a side angle, with its front facing to the right. The vehicle has a rectangular body with a slightly curved roofline. The wheels are visible at the bottom, with one wheel on the left and the other on the right. The car appears to be a sedan, and the drawing style is minimalistic, with no additional details or shading.\n",
      "The image shows a group of people seated at a table in what appears to be a restaurant. The main subject is a woman in the foreground, wearing a striped tank top, who is holding a fork and knife, seemingly about to eat. She has blonde hair and is smiling. In the background, there are three other individuals, one of whom is a man with glasses, another woman, and a third person whose face is not clearly visible. The table is set with plates and bowls containing food, including a salad with greens and possibly some fruits. The setting has a warm, cozy ambiance with a painting or mural on the wall behind them.\n",
      "The image features a wooden triangular frame with a spring mechanism attached to it. The spring is positioned horizontally and is compressed, with its ends resting on the two sides of the triangle. Two black shoes are placed on the bottom of the triangle, with their laces tied and pointing upwards. The background is a plain, light-colored wall. The overall arrangement suggests a simple, mechanical setup, possibly for a demonstration or experiment.\n",
      "The image features an abstract painting with a dynamic composition. The left side of the painting is dominated by vertical strokes of white, gray, and yellow, creating a sense of movement and depth. The right side is filled with horizontal strokes of red, pink, and white, adding contrast and vibrancy to the piece. The overall texture appears rough and textured, with visible brushstrokes and splatters of paint, giving the artwork a raw and expressive feel. The colors blend and overlap, creating a sense of unity despite the contrasting elements.\n"
     ]
    }
   ],
   "source": [
    "for out in outputs:\n",
    "    print(out.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4cddf-3051-4807-95c2-ec888018f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    # image_inputs, _ = process_vision_info(messages)\n",
    "    # inputs = processor(text=[text], images=image_inputs, padding=True)\n",
    "    \n",
    "    # # Inference: Generation of the output\n",
    "    # generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    # generated_ids_trimmed = [\n",
    "    #     out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    # ]\n",
    "    # output_text = processor.batch_decode(\n",
    "    #     generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    # )\n",
    "    # return output_text[0]\n",
    "# mm_data = {}\n",
    "# if image_inputs is not None:\n",
    "#     mm_data[\"image\"] = image_inputs\n",
    "# if video_inputs is not None:\n",
    "#     mm_data[\"video\"] = video_inputs\n",
    "\n",
    "# llm_inputs = {\n",
    "#     \"prompt\": prompt,\n",
    "#     \"multi_modal_data\": mm_data,\n",
    "\n",
    "#     # FPS will be returned in video_kwargs\n",
    "#     \"mm_processor_kwargs\": video_kwargs,\n",
    "# }\n",
    "\n",
    "# outputs = llm.generate([llm_inputs], sampling_params=sampling_params)\n",
    "# generated_text = outputs[0].outputs[0].text\n",
    "\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532950f2-95f2-4c6d-9a05-dae06fa289ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': './images/abstraction_4.jpg',\n",
       "    'resized_height': 560,\n",
       "    'resized_width': 1120},\n",
       "   {'type': 'text', 'text': 'Describe this image.'}]},\n",
       " {'role': 'assistant', 'content': [{'type': 'text', 'text': ''}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.common.templates import messages_template\n",
    "\n",
    "\n",
    "messages_template(data[0][\"image\"], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2620fc-cb76-483c-9188-e2fc11bee456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image features an abstract composition with vibrant colors and dynamic shapes. Dominating the background is a deep red hue, creating a striking contrast against the colorful elements in the foreground. Various flowers and leaves, rendered in shades of blue, green, pink, and purple, are scattered throughout the scene. These elements appear to be floating or moving, giving the impression of a lively, almost ethereal garden. The overall effect is one of movement and energy, as if the flowers are dancing in a field of light.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.common.templates import messages_template\n",
    "\n",
    "# default processor\n",
    "processor = AutoProcessor.from_pretrained(path)\n",
    "target_answer = \"\"\"Describe the visible content of this image shortly, objectively and factually **as a single, continuous paragraph of prose.** Focus on the main subjects or elements present. Note their key visual characteristics (e.g., color, shape, texture if prominent) and their spatial arrangement or relationship to one another. If any actions or interactions are depicted, describe them simply.\n",
    "\n",
    "**Crucially, do NOT use any structural formatting:**\n",
    "*   Avoid bullet points, numbered lists, or any list-like structures.\n",
    "*   Do not use introductory phrases that signal a list or structure (e.g., \"Key elements include:\", \"The characteristics are:\", \"Present are:\").\n",
    "*   Do not use section headings or labels within the description.\n",
    "\n",
    "Integrate all descriptive details smoothly into the narrative paragraph. Stick strictly to what is visually present. Avoid interpretations, assumptions, artistic analysis, or personal opinions. Make the description short.\n",
    "\"\"\"\n",
    "\n",
    "def make_answer(messages):\n",
    "    # Preparation for inference\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    return output_text[0]\n",
    "\n",
    "messages = messages_template(data[0][\"image\"], \"\")[:1]\n",
    "messages[0]['content'][1]['text'] = target_answer\n",
    "make_answer(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190ceb82-d097-47b8-b16b-c8c70e15e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_template = \"\"\"**Objective:** Generate an image description as a single, continuous paragraph. The core content of this description **MUST** be derived *exclusively* from the facts mentioned in the 'Human Transcription'. This content should then be expressed using the writing style (vocabulary, sentence structure, objective tone) demonstrated in the 'Target Model Style Example'.\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "1.  **Target Model Style Example (Style Reference ONLY):**\n",
    "    ```\n",
    "    {model_description}\n",
    "    ```\n",
    "    *(This text demonstrates HOW to phrase things objectively and descriptively. Its specific content (e.g., flowers, colors, light streaks) is COMPLETELY IRRELEVANT and MUST BE IGNORED unless explicitly mentioned in the Human Transcription.)*\n",
    "\n",
    "2.  **Human Transcription (The ONLY source of factual CONTENT):**\n",
    "    ```\n",
    "    {human_transcription}\n",
    "    ```\n",
    "    *(This dictates WHAT needs to be described. Ignore conversational style/opinions.)*\n",
    "\n",
    "**Task - Follow these steps STRICTLY:**\n",
    "\n",
    "1.  **Step 1: Extract Facts from Human Transcription.** Identify the key factual elements (objects, attributes, location, actions, setting like 'sunset') mentioned in the `Human Transcription`. List these facts internally. *Example: If Human says \"These are flowers against the backdrop of a sunset,\" the core facts are [flowers, sunset backdrop].*\n",
    "\n",
    "2.  **Step 2: Build Output based *ONLY* on Extracted Facts.** Construct sentences describing ONLY the facts identified in Step 1.\n",
    "\n",
    "3.  **Step 3: Apply Target Style to the Constructed Sentences.** Rephrase the sentences from Step 2 using vocabulary, sentence structure, and objective tone similar to the `Target Model Style Example`. Ensure the phrasing is sophisticated and descriptive, fitting the style.\n",
    "\n",
    "4.  **Step 4: Combine into a Single Paragraph.** Merge the stylistically adapted sentences into a single, coherent paragraph.\n",
    "\n",
    "**Examples of Correct Transformation:**\n",
    "\n",
    "*   **Example 1:**\n",
    "    *   Human Transcription: \"I like blue, bright blue, blue.\"\n",
    "    *   Correct Output: \"The image features a serene landscape dominated by a tranquil blue sky, which serves as a calming backdrop for the scene. The sky is adorned with soft, wispy clouds that gently drift across the horizon, adding a sense of depth and tranquility to the composition. Below the sky, the ground is covered in lush green grass, dotted with delicate white flowers that add a touch of purity and serenity to the landscape. The overall effect is one of peace and natural beauty, evoking a sense of calm and tranquility.\"\n",
    "\n",
    "*   **Example 2:**\n",
    "    *   Human Transcription: \"I see flowers or clovers of various shades against a red background.\"\n",
    "    *   Correct Output: \"The image showcases a vivid display of flowers or clovers in various shades against a striking red background. The flowers, rendered in hues of blue, green, pink, and purple, appear to be floating or moving, creating an impression of a lively, almost ethereal garden. The overall effect is one of movement and energy, as if the flowers are dancing in a field of light.\"\n",
    "\n",
    "*   **Example 3:**\n",
    "    *   Human Transcription: \"I also see a strange set of characters.\"\n",
    "    *   Correct Output: \"Beyond other potential visual elements within the composition, attention is drawn to the inclusion of a set of characters possessing a distinctly strange or unconventional appearance. These forms, characterized by their peculiar design, introduce an element of the unusual or unexpected into the visual field, contributing uniquely to the overall scene's perceived nature.\"\n",
    "\n",
    "\n",
    "**CRITICAL RULES:**\n",
    "\n",
    "*   **Human Facts are Paramount:** If a detail (object, color, interpretation like 'dynamic') exists in the `Target Model Style Example` but NOT in the `Human Transcription`, it **MUST NOT** appear in the output.\n",
    "*   **Content Matches Human Input:** The final description's subject matter must directly reflect what the human mentioned. If the human mentioned a 'sunset', the output MUST describe a sunset backdrop, using the target style. If the human only mentioned 'blue', the output MUST focus solely on 'blue'.\n",
    "*   **No Lists/Headings:** The final output must be a single paragraph.\n",
    "*   **Conciseness Reflects Input:** If the `Human Transcription` is very brief, the resulting description should also be brief, simply elevating the style of the few facts mentioned.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "Provide only the synthesized image description as a single paragraph, built exclusively from human-provided facts and expressed in the target model's style.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b492cda-0b1e-4450-b9c8-c0c89552eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = data.filter(lambda x: x if x[\"image\"] == 'abstraction_4.jpg' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3996085-894d-4cc6-ad8a-a80a9b14482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human description: The image of the flowers is intensely red.\n",
      "\n",
      "Model description: The image features a vibrant display of flowers in various shades of blue, green, pink, and purple, rendered against a deep red backdrop. These elements appear to be floating or moving, creating an impression of a lively, almost ethereal garden. The overall effect is one of movement and energy, as if the flowers are dancing in a field of light.\n",
      "\n",
      "\n",
      "Human description: This is a painting depicting flowers being blown by the wind in a field.\n",
      "\n",
      "Model description: The image depicts a painting of flowers being blown by the wind in a field. Dominating the background is a deep red hue, creating a striking contrast against the colorful elements in the foreground. Various flowers and leaves, rendered in shades of blue, green, pink, and purple, are scattered throughout the scene. These elements appear to be floating or moving, giving the impression of a lively, almost ethereal garden. The overall effect is one of movement and energy, as if the flowers are dancing in a field of light.\n",
      "\n",
      "\n",
      "Human description: An abstract painting on a red background with numerous details resembling flowers of various colors.\n",
      "\n",
      "Model description: The image features an abstract composition with vibrant colors and dynamic shapes. Dominating the background is a deep red hue, creating a striking contrast against the colorful elements in the foreground. Various flowers and leaves, rendered in shades of blue, green, pink, and purple, are scattered throughout the scene. These elements appear to be floating or moving, giving the impression of a lively, almost ethereal garden. The overall effect is one of movement and energy, as if the flowers are dancing in a field of light.\n",
      "\n",
      "\n",
      "Human description: Wildflowers against a red background.\n",
      "\n",
      "Model description: The image features a vibrant display of wildflowers against a striking red background. The flowers, rendered in shades of blue, green, pink, and purple, appear to be floating or moving, creating an impression of a lively, almost ethereal garden. The overall effect is one of movement and energy, as if the flowers are dancing in a field of light.\n",
      "\n",
      "\n",
      "Human description: A certain flower design on a field with a red background was also created using an iPad app.\n",
      "\n",
      "Model description: The image features a vibrant flower design set against a striking red background. The flowers, rendered in shades of blue, green, pink, and purple, appear to be floating or moving, creating an impression of a lively, almost ethereal garden. The overall effect is one of movement and energy, as if the flowers are dancing in a field of light.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in one[\"transcribation\"][-5:]:\n",
    "\n",
    "    print(f\"Human description: {item}\\n\")\n",
    "    messages = messages_template(data[0][\"image\"], \"\")[:1]\n",
    "    \n",
    "    messages[0]['content'][1]['text'] = rewrite_template.format(\n",
    "        model_description=\"The image features an abstract composition with vibrant colors and dynamic shapes. Dominating the background is a deep red hue, creating a striking contrast against the colorful elements in the foreground. Various flowers and leaves, rendered in shades of blue, green, pink, and purple, are scattered throughout the scene. These elements appear to be floating or moving, giving the impression of a lively, almost ethereal garden. The overall effect is one of movement and energy, as if the flowers are dancing in a field of light.\",\n",
    "        human_transcription=item\n",
    "    )\n",
    "    messages[0]['content'] = messages[0]['content'][1:]\n",
    "    print(f\"Model description: {make_answer(messages)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26e904f0-3562-46df-bd89-ef58a75874fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56aa9d09-7c5f-49d0-acab-70262a61594f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The painting depicts some kind of flowers in an abstract form against a red background, with the flowers appearing multicolored.',\n",
       " 'A painting of flowers on a red background, featuring flowers in green, blue, and white. The flowers at the bottom are smaller and more numerous than those at the top.',\n",
       " 'I like blue, bright blue, blue.',\n",
       " 'These are flowers against the backdrop of a sunset.',\n",
       " 'A red background with butterflies fluttering everywhere.',\n",
       " 'The painting of flowers on a red background is probably done in acrylics.',\n",
       " 'It looks like a painting by a modern artist, with a bunch of colorful flowers shining against a red background.',\n",
       " 'I think this is a sketch of a flower field against a sunset.',\n",
       " 'I see flowers or clovers of various shades against a red background.',\n",
       " 'I also see a strange set of characters.',\n",
       " 'This is a psychedelic image of a flower against a red background.',\n",
       " \"I think it's not really my taste in art at all.\",\n",
       " 'A multitude of abstract, translucent flowers set against a red background.',\n",
       " 'This is a painting with broad brushstrokes on a red background at the top.',\n",
       " 'a picture of flowers against a red background.',\n",
       " 'A painting with a red background features blue-green and white flowers, but the top part of the background is distinctly different.',\n",
       " 'Flowers or butterflies scattered randomly on a red background.',\n",
       " \"A lovely picture with flowers on a red background, or maybe they're butterflies, but no, they seem to be lilies.\",\n",
       " 'The image is probably some kind of drawing.',\n",
       " 'a line of hastily arranged flowers',\n",
       " 'A red background with some flowers.',\n",
       " 'I see an image with a pattern of flowers on a red background. The flowers create a sense of direction.',\n",
       " 'A painting of some flowers, not quite abstract, as if created by a neural network.',\n",
       " 'The image of the flowers is intensely red.',\n",
       " 'This is a painting depicting flowers being blown by the wind in a field.',\n",
       " 'An abstract painting on a red background with numerous details resembling flowers of various colors.',\n",
       " 'Wildflowers against a red background.',\n",
       " 'A certain flower design on a field with a red background was also created using an iPad app.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one[\"transcribation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5446035-10fe-421a-908c-1f218147c2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
