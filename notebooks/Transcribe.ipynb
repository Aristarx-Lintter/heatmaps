{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f3cbeb-172a-442c-b1a9-03535bb7fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U -q google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6750120-d8c3-42e4-b84f-eb5c24c6b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "audios = glob(\"./results/**/recorded_audio/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0590f7-57ff-43d9-ad84-e7f1f1683545",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbb43e6-8c67-475a-b823-bfb32960917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key='AIzaSyBydKXqTdLxAk1l4UtXLyhWF_uZDPjhL4c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b78a4d-6556-45ca-a407-9e2e597c02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "MODEL_NAME = \"gemini-1.5-flash\"\n",
    "PROMPT_TEXT = \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—à–∏—Ñ—Ä—É–π —ç—Ç–æ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç. –ò —É–±–µ—Ä–∏ –æ–±—Ä—ã–≤ –º—ã—Å–ª–∏ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–æ–Ω—Ü–µ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å\"\n",
    "\n",
    "def upload_audio_file(path):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Ñ–∞–π–ª–∞ API.\"\"\"\n",
    "    print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {path}...\")\n",
    "    try:\n",
    "        audio_file = genai.upload_file(path=path)\n",
    "        print(f\"–§–∞–π–ª '{audio_file.display_name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: {audio_file.name}).\")\n",
    "        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ñ–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Å–µ—Ä–≤–µ—Ä–æ–º\n",
    "        time.sleep(1) # –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∏–ª–∏ —É–±—Ä–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º\n",
    "        return audio_file\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(audio_file_object, prompt):\n",
    "    \"\"\"–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ Gemini.\"\"\"\n",
    "    if not audio_file_object:\n",
    "        return \"–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª.\"\n",
    "\n",
    "    print(f\"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ {audio_file_object.name}...\")\n",
    "    try:\n",
    "        model = genai.GenerativeModel(MODEL_NAME)\n",
    "        request_content = [prompt, audio_file_object]\n",
    "        response = model.generate_content(request_content, request_options={\"timeout\": 600}) # –£–≤–µ–ª–∏—á–∏–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ\n",
    "        if response.parts:\n",
    "             return response.text\n",
    "        else:\n",
    "             print(\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ç–µ–∫—Å—Ç–æ–≤—É—é —á–∞—Å—Ç—å. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\")\n",
    "             print(\"- –ê—É–¥–∏–æ –ø—É—Å—Ç–æ–µ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–∏—à–∏–Ω—É.\")\n",
    "             print(\"- –°—Ä–∞–±–æ—Ç–∞–ª–∏ —Ñ–∏–ª—å—Ç—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ response.prompt_feedback).\")\n",
    "             print(\"- –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ API.\")\n",
    "             print(\"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç:\", response)\n",
    "             if response.prompt_feedback and response.prompt_feedback.block_reason:\n",
    "                 return f\"–û—à–∏–±–∫–∞: –ó–∞–ø—Ä–æ—Å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω. –ü—Ä–∏—á–∏–Ω–∞: {response.prompt_feedback.block_reason}\"\n",
    "             return \"–û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ç–µ–∫—Å—Ç.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API Gemini: {e}\")\n",
    "        if hasattr(e, 'message'):\n",
    "             print(f\"   –î–µ—Ç–∞–ª–∏: {e.message}\")\n",
    "        return f\"–û—à–∏–±–∫–∞ API: {e}\"\n",
    "\n",
    "def delete_uploaded_file(file_object):\n",
    "    \"\"\"–£–¥–∞–ª—è–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å —Å–µ—Ä–≤–µ—Ä–æ–≤ Google.\"\"\"\n",
    "    if file_object:\n",
    "        print(f\"–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ {file_object.name}...\")\n",
    "        try:\n",
    "            genai.delete_file(file_object.name)\n",
    "            print(f\"–§–∞–π–ª {file_object.name} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.\")\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_object.name}: {e}\")\n",
    "\n",
    "async def process_wav(wav_file):\n",
    "    output = ''\n",
    "    if not os.path.exists(wav_file):\n",
    "        print(f\"–û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {wav_file}\")\n",
    "        return output\n",
    "\n",
    "    uploaded_file = None\n",
    "    try:\n",
    "        uploaded_file = upload_audio_file(wav_file)\n",
    "        if uploaded_file:\n",
    "            transcription = transcribe_audio(uploaded_file, PROMPT_TEXT)\n",
    "            print(\"\\n--- –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ---\")\n",
    "            print(transcription)\n",
    "            print(\"-----------------------------\\n\")\n",
    "            output = transcription\n",
    "            \n",
    "    finally:\n",
    "        if uploaded_file:\n",
    "            delete_uploaded_file(uploaded_file)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e1f0f-3bb9-4127-b76a-0bf51f995831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîä –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ:   0%|                                                                                                                   | 0/874 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: ./results/120225_2/recorded_audio/composition_6.jpg.wav...\n",
      "–§–∞–π–ª 'composition_6.jpg.wav' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: files/zeg0mtwdqzjh).\n",
      "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ files/zeg0mtwdqzjh...\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ---\n",
      "–ù–∞ –¥–∏–≤–∞–Ω–µ —Å—Ç–æ–∏—Ç —Å—Ç–æ–ª–∏–∫, –º–∏–Ω–∏-—Å—Ç–æ–ª–∏–∫ –¥–ª—è –µ–¥—ã. –¢—É—Ç —á–∞–π–Ω—ã–π —Å–µ—Ä–≤–∏–∑, –≤–∏–Ω–æ–≥—Ä–∞–¥, –æ—Ä–µ—Ö–∏ –∫–∞–∫–∏–µ-—Ç–æ, —Ü–≤–µ—Ç–æ–∫.\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ files/zeg0mtwdqzjh...\n",
      "–§–∞–π–ª files/zeg0mtwdqzjh —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: ./results/240125/recorded_audio/social_2.jpg.wav...\n",
      "–§–∞–π–ª 'social_2.jpg.wav' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: files/6numxr1kbynq).\n",
      "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ files/6numxr1kbynq...\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ---\n",
      "–≠—Ç–æ –ª—é–¥–∏ –≥—Ä–µ–±—É—Ç –Ω–∞ –ª–æ–¥–∫–µ. –í—Ä—è–¥ –ª–∏ –æ–Ω–∏ –ø—Ä–∏ —ç—Ç–æ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã, –Ω–æ —ç—Ç–æ –∫–∞–∫–æ–µ-—Ç–æ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ, –≤–∏–¥–∏–º–æ. –ù–µ –∑–Ω–∞—é, –∫–∞–∫–∏–µ –∏–≥—Ä—ã...\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ files/6numxr1kbynq...\n",
      "–§–∞–π–ª files/6numxr1kbynq —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: ./results/121124/recorded_audio/social_4.jpg.wav...\n",
      "–§–∞–π–ª 'social_4.jpg.wav' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: files/e3qfmc9gzsir).\n",
      "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ files/e3qfmc9gzsir...\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "   –î–µ—Ç–∞–ª–∏: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ---\n",
      "–û—à–∏–±–∫–∞ API: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "-----------------------------\n",
      "\n",
      "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ files/e3qfmc9gzsir...\n",
      "–§–∞–π–ª files/e3qfmc9gzsir —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: ./results/120225_2/recorded_audio/composition_4.jpg.wav...\n",
      "–§–∞–π–ª 'composition_4.jpg.wav' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: files/wr8u61y4krtq).\n",
      "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ files/wr8u61y4krtq...\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "]\n",
      "   –î–µ—Ç–∞–ª–∏: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ---\n",
      "–û—à–∏–±–∫–∞ API: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "]\n",
      "-----------------------------\n",
      "\n",
      "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ files/wr8u61y4krtq...\n",
      "–§–∞–π–ª files/wr8u61y4krtq —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: ./results/240125/recorded_audio/disrupted_3.jpg.wav...\n",
      "–§–∞–π–ª 'disrupted_3.jpg.wav' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: files/o0j4m9i8v4ca).\n",
      "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ files/o0j4m9i8v4ca...\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "   –î–µ—Ç–∞–ª–∏: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ---\n",
      "–û—à–∏–±–∫–∞ API: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "-----------------------------\n",
      "\n",
      "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ files/o0j4m9i8v4ca...\n",
      "–§–∞–π–ª files/o0j4m9i8v4ca —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: ./results/121124/recorded_audio/abstraction_2.jpg.wav...\n",
      "–§–∞–π–ª 'abstraction_2.jpg.wav' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: files/ufgm6nonsg0p).\n",
      "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ files/ufgm6nonsg0p...\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "   –î–µ—Ç–∞–ª–∏: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ---\n",
      "–û—à–∏–±–∫–∞ API: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "-----------------------------\n",
      "\n",
      "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ files/ufgm6nonsg0p...\n",
      "–§–∞–π–ª files/ufgm6nonsg0p —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: ./results/120225_2/recorded_audio/abstraction_1.jpg.wav...\n",
      "–§–∞–π–ª 'abstraction_1.jpg.wav' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: files/alc01hmbimns).\n",
      "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ files/alc01hmbimns...\n",
      "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n",
      "   –î–µ—Ç–∞–ª–∏: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ---\n",
      "–û—à–∏–±–∫–∞ API: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n",
      "-----------------------------\n",
      "\n",
      "–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ files/alc01hmbimns...\n",
      "–§–∞–π–ª files/alc01hmbimns —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: ./results/240125/recorded_audio/composition_5.jpg.wav...\n",
      "–§–∞–π–ª 'composition_5.jpg.wav' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω (ID: files/1b032vzmi62n).\n",
      "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –¥–ª—è —Ñ–∞–π–ª–∞ files/1b032vzmi62n...\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from asyncio import Semaphore\n",
    "from tqdm.asyncio import tqdm_asyncio  # –≤–µ—Ä—Å–∏—è tqdm, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∞—è async\n",
    "# –∏–ª–∏: from tqdm import tqdm_asyncio ‚Äî –µ—Å–ª–∏ –æ–±—ã—á–Ω—ã–π tqdm —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n",
    "\n",
    "semaphore = Semaphore(4)\n",
    "\n",
    "async def limited_process(wav_file):\n",
    "    async with semaphore:\n",
    "        return await process_wav(wav_file)\n",
    "\n",
    "async def processor(audios):\n",
    "    tasks = [limited_process(wav) for wav in audios]\n",
    "    results = await tqdm_asyncio.gather(*tasks, desc=\"üîä –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ\")\n",
    "    return results\n",
    "\n",
    "results = await processor(audios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256dba7-0a8a-444f-a2c6-3a6082f43847",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0743bf1e-4bca-4a58-ae32-d548b1d2de83",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from asyncio import Semaphore\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
    "API_KEY = os.environ.get(\"load_dotenv\") # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π API-–∫–ª—é—á OpenAI\n",
    "API_URL = 'https://api.openai.com/v1/audio/transcriptions'\n",
    "MODEL_NAME = 'gpt-4o-transcribe'\n",
    "PROMPT_TEXT = (\n",
    "    \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—à–∏—Ñ—Ä—É–π —ç—Ç–æ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç. \"\n",
    "    \"–ò —É–±–µ—Ä–∏ –æ–±—Ä—ã–≤ –º—ã—Å–ª–∏ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–æ–Ω—Ü–µ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efdc335f-314b-403a-a2a6-a049e9c637e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MAX_CONCURRENT = 15  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
    "\n",
    "semaphore = Semaphore(MAX_CONCURRENT)\n",
    "\n",
    "async def transcribe_audio(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ gpt-4o-transcribe.\n",
    "    –ü–µ—Ä–µ–¥–∞—ë—Ç –ø—Ä–æ–º–ø—Ç PROMPT_TEXT –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return f\"[!] –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–æ—Ä–º—É –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "    data = aiohttp.FormData()\n",
    "    data.add_field(\"model\", MODEL_NAME)\n",
    "    data.add_field(\"prompt\", PROMPT_TEXT)\n",
    "    data.add_field(\"language\", \"ru\")\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç wav)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data.add_field(\n",
    "            \"file\",\n",
    "            f,\n",
    "            filename=os.path.basename(file_path),\n",
    "            content_type=\"audio/wav\"\n",
    "        )\n",
    "        \n",
    "        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —á–∏—Å–ª–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\n",
    "        async with semaphore:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(API_URL, headers=headers, data=data) as response:\n",
    "                    if response.status == 200:\n",
    "                        result = await response.json()\n",
    "                        return result.get(\"text\", \"\")\n",
    "                    else:\n",
    "                        error_text = await response.text()\n",
    "                        raise Exception(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ {file_path}: {error_text}\")\n",
    "\n",
    "async def transcribe_batch(audio_files):\n",
    "    \"\"\"\n",
    "    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –≥—Ä—É–ø–ø—É –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤, –æ—Ç–æ–±—Ä–∞–∂–∞—è –ø—Ä–æ–≥—Ä–µ—Å—Å —Å –ø–æ–º–æ—â—å—é tqdm.\n",
    "    \"\"\"\n",
    "    tasks = [transcribe_audio(file) for file in audio_files]\n",
    "    results = await tqdm_asyncio.gather(*tasks, desc=\"üîä –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cf434e-e02f-40e6-a9a9-e2926b1ca18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîä –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 874/874 [01:20<00:00, 10.82it/s]\n"
     ]
    }
   ],
   "source": [
    "results = await transcribe_batch(audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dcfb8c-9a36-4c27-bd15-d267875c6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_files = glob(\"./images_asc/*asc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a9126cc-7a11-4598-b149-a298a707962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposes = set(asc_files)\n",
    "dict_dataset = {}\n",
    "\n",
    "for audio, transcribation in zip(audios, results):\n",
    "    image_name, human_id = audio.split(\"/\")[-1][:-4], audio.split(\"/\")[-3]\n",
    "    \n",
    "    proposed_id = \"undefined\"\n",
    "    for asc_file in proposes:\n",
    "        if asc_file.split(\"/\")[-1][:-4] == human_id:\n",
    "            proposed_id = asc_file\n",
    "            # proposes.remove(asc_file)\n",
    "            break\n",
    "\n",
    "    if human_id not in dict_dataset:\n",
    "        dict_dataset[human_id] = {}\n",
    "    dict_dataset[human_id][image_name] = {\n",
    "            \"asc_file\": proposed_id,\n",
    "            'transcribation': transcribation,\n",
    "            'audio_file': audio\n",
    "        }\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "127e46ec-f4b8-4820-8a87-ec42bfa17d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposes = set(asc_files)\n",
    "\n",
    "print(len(proposes))\n",
    "proposes.remove('./images_asc/AntonK.asc')\n",
    "len(proposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd78177-ebba-4291-810e-c109100e1be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'250225_3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_files = glob(\"./images_asc/*asc\")\n",
    "asc_files[0].split(\"/\")[-1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "576e5e44-176f-43c6-adaa-838f0f734871",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "  Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting lazy-loader>=0.3\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.15.2)\n",
      "Collecting pooch>=1.5\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.6/64.6 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.10.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (10.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.6->mne) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Installing collected packages: lazy-loader, pooch, mne\n",
      "Successfully installed lazy-loader-0.4 mne-1.9.0 pooch-1.8.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6fc30c63-8e45-42d6-8a4b-9b868e2c4bfa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /workspace/images_asc/11124.asc\n",
      "Pixel coordinate data detected.Pass `scalings=dict(eyegaze=1e3)` when using plot method to make traces more legible.\n",
      "Pupil-size area detected.\n",
      "There are 60 recording blocks in this file. Times between blocks will be annotated with BAD_ACQ_SKIP.\n",
      "Used Annotations descriptions: ['FUCK', 'SYNCTIME', 'TRACKER_TIME 10 2747946.704', 'TRACKER_TIME 11 2815533.546', 'TRACKER_TIME 12 2882486.810', 'TRACKER_TIME 3 2271440.372', 'TRACKER_TIME 4 2338543.433', 'TRACKER_TIME 5 2408180.356', 'TRACKER_TIME 6 2475783.643', 'TRACKER_TIME 7 2544153.428', 'TRACKER_TIME 8 2612006.973', 'TRACKER_TIME 9 2679060.012', 'timeout']\n",
      "Multiple event values for single event times found. Creating new event value to reflect simultaneous events.\n",
      "Not setting metadata\n",
      "209 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "[!] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞ 59\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_784/1763591904.py:47: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.\n",
      "  plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
      "/tmp/ipykernel_784/1763591904.py:50: UserWarning: The figure layout has changed to tight\n",
      "  fig.tight_layout(pad=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 1 events and 20001 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_784/1763591904.py:58: RuntimeWarning: All epochs were dropped!\n",
      "You might need to alter reject/flat-criteria or drop bad channels to avoid this. You can use Epochs.plot_drop_log() to see which channels are responsible for the dropping of epochs.\n",
      "  fig = plot_gaze(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from PIL import Image, ImageChops\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.viz.eyetracking import plot_gaze\n",
    "\n",
    "\n",
    "def crop_whitespace(im, threshold=10):\n",
    "    \"\"\"\n",
    "    –û–±—Ä–µ–∑–∞–µ—Ç –±–µ–ª—ã–µ (–∏–ª–∏ –ø–æ—á—Ç–∏ –±–µ–ª—ã–µ) –∫—Ä–∞—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n",
    "    threshold ‚Äì –ø–æ—Ä–æ–≥, –≤—ã—à–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –ø–∏–∫—Å–µ–ª—å —Å—á–∏—Ç–∞–µ—Ç—Å—è –±–µ–ª—ã–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10).\n",
    "    \"\"\"\n",
    "    # –°–æ–∑–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≥–æ –∂–µ —Ä–∞–∑–º–µ—Ä–∞ —Å –±–µ–ª—ã–º —Ñ–æ–Ω–æ–º\n",
    "    bg = Image.new(im.mode, im.size, 255)\n",
    "    # –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏ –±–µ–ª—ã–º —Ñ–æ–Ω–æ–º\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    # –ò–Ω–æ–≥–¥–∞ –ø–æ–ª–µ–∑–Ω–æ —É—Å–∏–ª–∏—Ç—å –∫–æ–Ω—Ç—Ä–∞—Å—Ç, —á—Ç–æ–±—ã –º–µ–ª–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –Ω–µ –º–µ—à–∞–ª–∏:\n",
    "    diff = diff.point(lambda x: 0 if x < threshold else x)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        return im.crop(bbox)\n",
    "    return im\n",
    "\n",
    "def clean_figure(fig):\n",
    "    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ—Å–µ–π –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ\n",
    "    axes = fig.get_axes()\n",
    "\n",
    "    # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ 0-—è –æ—Å—å ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞, –∞ 1-—è (–∏ –¥–∞–ª–µ–µ) ‚Äî –ª–µ–≥–µ–Ω–¥—ã / —Ü–≤–µ—Ç–±–∞—Ä—ã\n",
    "    main_ax = axes[0]\n",
    "\n",
    "    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –æ—Å–∏, –∫—Ä–æ–º–µ –≥–ª–∞–≤–Ω–æ–π\n",
    "    for ax in axes[1:]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "    # –ü–æ–ª–Ω–æ—Å—Ç—å—é —É–±–∏—Ä–∞–µ–º —Ä–∞–º–∫—É, –º–µ—Ç–∫–∏ –∏ –ø—Ä.\n",
    "    main_ax.set_xticks([])\n",
    "    main_ax.set_yticks([])\n",
    "    main_ax.set_xlabel(\"\")\n",
    "    main_ax.set_ylabel(\"\")\n",
    "    main_ax.set_title(\"\")\n",
    "    main_ax.set_frame_on(False)\n",
    "\n",
    "    # –¢–∞–∫–∂–µ –ø–æ–¥—á–∏—â–∞–µ–º –æ—Ç—Å—Ç—É–ø—ã\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    plt.margins(0, 0)\n",
    "    # –ú–æ–∂–Ω–æ –µ—â—ë –ø–æ–¥–∂–∞—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "    fig.tight_layout(pad=0)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def render_heatmap_pil(epoch, px_width=1920, px_height=1080):\n",
    "    \"\"\"\n",
    "    –†–∏—Å—É–µ—Ç —Ö–∏—Ç–º–∞–ø—É –ø–æ –¥–∞–Ω–Ω—ã–º —ç–ø–æ—Ö–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ—ë –∫–∞–∫ PIL.Image (grayscale).\n",
    "    \"\"\"\n",
    "    fig = plot_gaze(\n",
    "        epoch,\n",
    "        width=px_width,\n",
    "        height=px_height,\n",
    "        cmap='gray',\n",
    "        vlim=(0.000003, None),\n",
    "        sigma=25.0,\n",
    "        show=False\n",
    "    )\n",
    "    # –ß–∏—Å—Ç–∏–º –≤—Å—ë –ª–∏—à–Ω–µ–µ, –≤ —Ç–æ–º —á–∏—Å–ª–µ colorbar\n",
    "    fig = clean_figure(fig)\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±—É—Ñ–µ—Ä\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    raw_image = Image.open(buf).convert(\"L\")  # –ì—Ä–µ–π—Å–∫–µ–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "\n",
    "    # –û–±—Ä–µ–∑–∫–∞ –±–µ–ª—ã—Ö –∫—Ä–∞—ë–≤\n",
    "    return crop_whitespace(raw_image)\n",
    "\n",
    "\n",
    "async def async_render_heatmap_pil(epoch, px_width=1920, px_height=1080):\n",
    "    \"\"\"\n",
    "    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è render_heatmap_pil —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º asyncio.to_thread.\n",
    "    \"\"\"\n",
    "    return await asyncio.to_thread(render_heatmap_pil, epoch, px_width, px_height)\n",
    "\n",
    "async def process_asc_async(et_fpath):\n",
    "    \"\"\"\n",
    "    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª .asc:\n",
    "     - —á–∏—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–π—Ç—Ä–µ–∫–µ—Ä–∞,\n",
    "     - –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–∞–π–ª–æ–≤,\n",
    "     - –¥–ª—è 60 –∏—Å–ø—ã—Ç–∞–Ω–∏–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Ä–µ–Ω–¥–µ—Ä–∏—Ç —Ö–∏—Ç–º–∞–ø—ã.\n",
    "     \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏:\n",
    "      \"image\": –∏–º—è —Ñ–∞–π–ª–∞ (–∏–∑ .asc),\n",
    "      \"suffix\": —Ç–∏–ø –∏—Å–ø—ã—Ç–∞–Ω–∏—è (freeview –∏–ª–∏ description),\n",
    "      \"heatmap\": PIL.Image —Å —Ö–∏—Ç–º–∞–ø–æ–π.\n",
    "    \"\"\"\n",
    "    # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∞–π—Ç—Ä–µ–∫–µ—Ä–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–ø–æ—Ö\n",
    "    raw_et = mne.io.read_raw_eyelink(et_fpath, create_annotations=[\"messages\"], apply_offsets=True)\n",
    "    raw_et.annotations.rename({'BAD_ACQ_SKIP': 'FUCK'})\n",
    "    events, event_dict = mne.events_from_annotations(raw_et)\n",
    "    epochs = mne.Epochs(\n",
    "        raw_et, events=events, event_id=event_dict,\n",
    "        tmin=0, tmax=20, baseline=None, event_repeated='merge', reject_by_annotation=True\n",
    "    )\n",
    "    \n",
    "    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –∏–∑ .asc (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —Å—Ç—Ä–æ–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –Ω—É–∂–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω)\n",
    "    with open(et_fpath, 'r', encoding='utf-8') as f:\n",
    "        file_names = []\n",
    "        for line in f:\n",
    "            match = re.search(r'!V TRIAL_VAR file_name\\s+(\\S+)', line)\n",
    "            if match:\n",
    "                file_names.append(match.group(1))\n",
    "    \n",
    "    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Ö–∏—Ç–º–∞–ø\n",
    "    metadata = []\n",
    "    tasks = []\n",
    "    for i in range(60):\n",
    "        try:\n",
    "            epoch = epochs[\"FUCK\"][i]\n",
    "        except IndexError:\n",
    "            print(f\"[!] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞ {i}\")\n",
    "            continue\n",
    "        \n",
    "        trial_file = file_names[i]\n",
    "        trial = os.path.splitext(trial_file)[0]\n",
    "        suffix = \"freeview\" if i % 2 == 0 else \"description\"\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Å–±–æ—Ä–∫–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞\n",
    "        metadata.append({\n",
    "            \"image\": trial_file,\n",
    "            \"suffix\": suffix\n",
    "        })\n",
    "        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ —Ö–∏—Ç–º–∞–ø—ã\n",
    "        tasks.append(asyncio.create_task(async_render_heatmap_pil(epoch)))\n",
    "    \n",
    "    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á\n",
    "    heatmaps = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "    examples = []\n",
    "    for meta, heatmap in zip(metadata, heatmaps):\n",
    "        examples.append({\n",
    "            \"image\": meta[\"image\"],\n",
    "            \"suffix\": meta[\"suffix\"],\n",
    "            \"heatmap\": heatmap\n",
    "        })\n",
    "    return examples\n",
    "\n",
    "examples = await process_asc_async(\"images_asc/11124.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9cc4ad66-ff91-45e4-a9bf-1310e6ff9fa3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [09:33<00:00, 19.11s/it]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for human_id in tqdm(dict_dataset):\n",
    "    if f\"./images_asc/{human_id}.asc\" in proposes:\n",
    "        heatmaps = await process_asc_async(f\"./images_asc/{human_id}.asc\")\n",
    "        clear_output()\n",
    "        for heat in heatmaps:\n",
    "            if heat[\"image\"] in dict_dataset[human_id]:\n",
    "                dict_dataset[human_id][heat[\"image\"]][heat['suffix']] = heat['heatmap']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4c445cff-1c1b-4f97-bef6-7e78eb26c0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_id': '1411241',\n",
       " 'asc_file': './images_asc/1411241.asc',\n",
       " 'transcribation': '–°–Ω–∞—á–∞–ª–∞ —è –ø–æ–¥—É–º–∞–ª–∞, —á—Ç–æ —ç—Ç–æ –∫–∞–∫–∏–µ-—Ç–æ —Ä–µ–∑–∏–Ω–∫–∏ –¥–ª—è –≤–æ–ª–æ—Å, –º–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —ç—Ç–æ –∫–∞–∫–æ–µ-—Ç–æ –∏—Å–∫—É—Å—Å—Ç–≤–æ, —ç—Ç–æ –∫–∞–∫–∞—è-—Ç–æ –∫–∞—Ä—Ç–∏–Ω–∞ —Å –∑–µ–ª—ë–Ω–æ-–∂—ë–ª—Ç—ã–º –º–æ—Ç–∏–≤–æ–º.',\n",
       " 'audio_file': './results/1411241/recorded_audio/abstraction_1.jpg.wav',\n",
       " 'suffix': 'description',\n",
       " 'heatmap': <PIL.Image.Image image mode=L size=640x360>,\n",
       " 'freeview': <PIL.Image.Image image mode=L size=640x360>,\n",
       " 'description': <PIL.Image.Image image mode=L size=640x360>}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dataset[\"1411241\"]['abstraction_1.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e7a1d75d-3b8a-4cee-b2ce-a3a3fc7559cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_id': '270225_1',\n",
       " 'asc_file': './images_asc/270225_1.asc',\n",
       " 'transcribation': '–ú—É–∂—á–∏–Ω–∞ –ª–µ—Ç —Ç—Ä–∏–¥—Ü–∞—Ç–∏ —Å –∫–æ–ª—å—Ü–∞–º–∏ –Ω–∞ –ø–∞–ª—å—Ü–∞—Ö, –∫—Ä–∏—á–∞—â–∏–π –æ—Ç –∑–ª–æ—Å—Ç–∏ –∏–ª–∏ –æ—Ç –≥—Ä—É—Å—Ç–∏.',\n",
       " 'audio_file': './results/270225_1/recorded_audio/social_4.jpg.wav',\n",
       " 'suffix': 'freeview',\n",
       " 'heatmap': <PIL.Image.Image image mode=L size=640x360>,\n",
       " 'freeview': <PIL.Image.Image image mode=L size=640x360>}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dataset[human_id][image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc056c06-85ca-4341-aee1-b345c339b3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886930a72b5c476c897cb0083df15db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[‚úì] HF dataset —Å–æ—Ö—Ä–∞–Ω—ë–Ω: eyetracking_hf_dataset\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "examples = []\n",
    "\n",
    "for human_id in dict_dataset:\n",
    "    for image in dict_dataset[human_id]:\n",
    "        if \"heatmap\" in dict_dataset[human_id][image]:\n",
    "            dummy_dict = dict_dataset[human_id][image].copy()\n",
    "            del dummy_dict[\"heatmap\"]\n",
    "\n",
    "            ones = []\n",
    "            if 'freeview' in dummy_dict:\n",
    "                ones.append({\n",
    "                'human_id': human_id,\n",
    "                'image': image,\n",
    "                'suffix': dummy_dict['suffix'],\n",
    "                'heatmap': dummy_dict['freeview'],\n",
    "                'transcribation': dummy_dict['transcribation'],\n",
    "                'audio_file': dummy_dict['audio_file'],\n",
    "                \"asc_file\": dummy_dict['asc_file'],\n",
    "            })\n",
    "            if 'description' in dummy_dict:\n",
    "                ones.append({\n",
    "                'human_id': human_id,\n",
    "                'image': image,\n",
    "                'suffix': dummy_dict['suffix'],\n",
    "                'heatmap': dummy_dict['description'],\n",
    "                'transcribation': dummy_dict['transcribation'],\n",
    "                'audio_file': dummy_dict['audio_file'],\n",
    "                \"asc_file\": dummy_dict['asc_file'],\n",
    "            })\n",
    "            examples.extend(ones)\n",
    "\n",
    "dataset = Dataset.from_list(examples)\n",
    "dataset.save_to_disk(\"eyetracking_hf_dataset\")\n",
    "print(f\"[‚úì] HF dataset —Å–æ—Ö—Ä–∞–Ω—ë–Ω: eyetracking_hf_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c5348546-2ec3-47fb-b6fb-b6f6427951f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f74bc8b3e74fa7bf634af2c8e1e2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desired_text = \"–ù–∞ –∫–∞—Ä—Ç–∏–Ω–µ —Ç—Ä–∏ –º—É–∂—á–∏–Ω—ã —Å—Ä–µ–¥–Ω–µ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞ –ø–æ —Ü–µ–Ω—Ç—Ä—É –∏ —Å–∑–∞–¥–∏ –µ—â–µ –æ–¥–∏–Ω —Å—Ç–æ–∏—Ç, –æ–Ω–∏ –Ω–∞ –∫—É—Ö–Ω–µ –≤ –∫–∞–∫–æ–π-—Ç–æ –∫–≤–∞—Ä—Ç–∏—Ä–µ.\"\n",
    "\n",
    "filtered_dataset = dataset.filter(lambda example: example[\"transcribation\"] == desired_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48b287-d465-49f8-9e6c-849de6bb31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(examples)\n",
    "dataset.save_to_disk(\"eyetracking_hf_dataset\")\n",
    "print(f\"[‚úì] HF dataset —Å–æ—Ö—Ä–∞–Ω—ë–Ω: eyetracking_hf_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "21748830-4306-4056-800a-7baa0fd73c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['human_id', 'image', 'suffix', 'heatmap', 'transcribation', 'audio_file', 'asc_file'],\n",
       "    num_rows: 1711\n",
       "})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7839df3b-d3e2-4161-938d-82a5221264f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import re\n",
    "from openai import AsyncOpenAI\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "def extract_json_variations(response_text: str) -> list:\n",
    "    \"\"\"\n",
    "    –ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON-–º–∞—Å—Å–∏–≤ –∏–∑ markdown-—Ñ–æ—Ä–º–∞—Ç–∞ —Ç–∏–ø–∞ ```json [ ... ] ``` –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–∫ list[str]\n",
    "    \"\"\"\n",
    "    # –£–¥–∞–ª—è–µ–º markdown-–±–ª–æ–∫–∏\n",
    "    match = re.search(r\"```(?:json)?\\s*(\\[.*?\\])\\s*```\", response_text, re.DOTALL)\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    json_str = match.group(1)\n",
    "\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ (–Ω–æ–≤—ã–π —Å–ø–æ—Å–æ–±)\n",
    "client = AsyncOpenAI(api_key=API_KEY)\n",
    "\n",
    "# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "semaphore = asyncio.Semaphore(200)\n",
    "\n",
    "async def generate_variations(text: str) -> list:\n",
    "    prompt = (\n",
    "        \"Generate 10 diverse and natural-sounding English paraphrases for the following text. \"\n",
    "        \"Return the result strictly as a JSON array of 10 strings.\\n\\n\"\n",
    "        f\"Text: {text}\"\n",
    "    )\n",
    "\n",
    "    async with semaphore:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates English paraphrases.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "        )\n",
    "\n",
    "    return extract_json_variations(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9d04b5f6-69b5-4909-81a0-9e0a3d40fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.asyncio import tqdm_asyncio  # –Ω—É–∂–µ–Ω tqdm>=4.66\n",
    "from tqdm import tqdm\n",
    "\n",
    "async def main(unique_transcriptions):\n",
    "    all_variations = {}\n",
    "\n",
    "    tasks = []\n",
    "    for text in unique_transcriptions:\n",
    "        task = asyncio.create_task(generate_variations(text))\n",
    "        tasks.append((text, task))\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–≥—Ä–µ—Å—Å–±–∞—Ä\n",
    "    pbar = tqdm(total=len(tasks), desc=\"Generating paraphrases\")\n",
    "\n",
    "    for original, task in tasks:\n",
    "        result = await task\n",
    "        all_variations[original] = result\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    return all_variations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "db9ae3a3-f46a-43b5-ad72-2823cc887d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_transes = set(dataset[\"transcribation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e2b62621-9682-4fca-91dc-e188f2cf8105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating paraphrases: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 870/870 [00:41<00:00, 21.18it/s]\n"
     ]
    }
   ],
   "source": [
    "all_variations = await main(unique_transes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c8d0668a-c0f3-4f55-acec-9c0cae6bf932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1711/1711 [00:04<00:00, 391.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "def expand_dataset(original_dataset: Dataset, variations_map: dict) -> Dataset:\n",
    "    \"\"\"\n",
    "    –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç, –∑–∞–º–µ–Ω—è—è –ø–æ–ª–µ 'transcribation' –Ω–∞ 10 –≤–∞—Ä–∏–∞—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏.\n",
    "    \n",
    "    :param original_dataset: –∏—Å—Ö–æ–¥–Ω—ã–π HuggingFace Dataset\n",
    "    :param variations_map: —Å–ª–æ–≤–∞—Ä—å {–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è: [–≤–∞—Ä–∏–∞—Ü–∏–∏]}\n",
    "    :return: –Ω–æ–≤—ã–π Dataset, —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π x10\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "\n",
    "    for example in tqdm(original_dataset):\n",
    "        orig_trans = example[\"transcribation\"]\n",
    "        if orig_trans not in variations_map:\n",
    "            continue  # —Å–∫–∏–ø–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤–∞—Ä–∏–∞—Ü–∏–∏\n",
    "\n",
    "        for new_trans in variations_map[orig_trans]:\n",
    "            new_example = deepcopy(example)\n",
    "            new_example[\"transcribation\"] = new_trans\n",
    "            new_data.append(new_example)\n",
    "\n",
    "    return Dataset.from_list(new_data)\n",
    "\n",
    "\n",
    "set_dataset_off = expand_dataset(dataset, all_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b495bd71-36ef-4e3e-929b-91a3f9ac0502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b8e50c7aaf4d48955119b2f405e386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/16380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_dataset_off.save_to_disk(\"set_eye_dataset_off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d3e793b4-e4d7-41ef-8986-63f0e0615c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['human_id', 'image', 'suffix', 'heatmap', 'transcribation', 'audio_file', 'asc_file'],\n",
       "    num_rows: 16380\n",
       "})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_dataset_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859a1c5-3509-436d-a071-37726ed9ff9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
